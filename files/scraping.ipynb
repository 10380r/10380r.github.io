{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "----------\n",
    "# Webスクレイピング  \n",
    "---------\n",
    "#### 概要\n",
    "Webスクレイピングとは **データ取得** をする際に利用する技術    \n",
    "プログラムを使ってWebからコンテンツをダウンロードすること  \n",
    "例： GoogleはスクレイピングでWebページの索引を作成  \n",
    "  \n",
    "  -----\n",
    "Chromeの検証機能を使い、htmlを読みながら解析して欲しい要素をパースするので、ある程度のhtmlの知識が必要になります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "-----\n",
    "#### データ取得の開発フロー  \n",
    "どのようなデータが必要かを考案  \n",
    "そのデータを取得できるAPIがあるか調査  \n",
    "[API](https://www.sejuku.net/blog/7087)がなかった場合スクレイピングを実装   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "-----\n",
    "#### なぜスクレイピングの優先度が低いのか  \n",
    "APIの方が実装コストが低い  \n",
    "Webスクレイピングは実装コストがAPIと比べて高く，法律的な制限も存在する  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "------\n",
    "#### <a style='color:red'>**スクレイピングに伴う注意事項**</a>\n",
    "以下通読願います。  \n",
    "[Webスクレイピングの注意事項一覧](https://qiita.com/nezuq/items/c5e827e1827e7cb29011)  \n",
    "\n",
    "実際、こんな事件がありました。  \n",
    "-->  [岡崎市立中央図書館事件](https://ja.wikipedia.org/wiki/%E5%B2%A1%E5%B4%8E%E5%B8%82%E7%AB%8B%E4%B8%AD%E5%A4%AE%E5%9B%B3%E6%9B%B8%E9%A4%A8%E4%BA%8B%E4%BB%B6)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## スクレイピングの工程\n",
    "\n",
    "_『[yahooの速報](https://news.yahoo.co.jp/flash)から各ニュースの速報からタイトルを出力してみましょう  』_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "  \n",
    "1.必要なライブラリのインポート  \n",
    "\n",
    "・requests \n",
    ">requestsはhttpリクエストを送るためのライブラリ\n",
    "\n",
    "・BeautifulSoup\n",
    ">スクレイピングに特化したライブラリ  \n",
    "他にも、`selenium`, `scarapy`, `PhantomJS`などが存在。  \n",
    "用途に合わせてライブラリを変える。\n",
    "\n",
    "```python\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "2.urlの指定\n",
    "```python\n",
    "url = 'https://news.yahoo.co.jp/flash'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "3.resという変数にrequestsライブラリのgetメソッドを使用してレスポンスの情報を格納\n",
    "```python\n",
    "res = requests.get(url)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "4.Beautiful Soupを使用してスクレイピング\n",
    "```python\n",
    "soup = BeautifulSoup(res.content)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "5.抽出したい要素を指定し、変数に格納\n",
    "\n",
    "\n",
    "`オブジェクト.find('htmlのタグ', 'htmlのクラス')`\n",
    "\n",
    "```python\n",
    "parent = soup.find('div', 'newsFeed')\n",
    "targets = parent.findAll('div', 'newsFeed_item_title')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "6.findAllから返されるオブジェクトはリストなので `.text` と指定しての出力ができない  \n",
    "そのためループ処理して、そこから `.text` として出力させる\n",
    "```python\n",
    "for target in targets:\n",
    "    print(target.text)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "tds = [1,2,3]\n",
    "print(tds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "「死へのカウントダウン」 トランプ氏、イラン司令官の最期を語る\n",
      "東野幸治、紳助さんに“クレーム”「僕が一番言いたいのは…」\n",
      "サッカー＝ラツィオ11連勝、首位ユベントスに接近\n",
      "ラグビー欧州王者サラセンズ、国内2部リーグ降格へ 年俸規定に違反\n",
      "消えない不安、そして葛藤も……。西日本豪雨で被災した野村町の3人が果たした再スタート＜後編＞\n",
      "酒気帯び運転疑い米兵逮捕、沖縄　石川署、国道の中央分離帯に衝突\n",
      "最後のセンター試験 ２日目\n",
      "情報漏えい容疑の空自元幹部、データを特別防衛秘密として登録せず\n",
      "妊娠発覚の加藤紗里、父親は「（元）旦那ですよね？」〈dot.〉\n",
      "ロシア・プーチン大統領、４年後の任期満了で退任を示唆\n",
      "サッカー＝ドルトムントのハーランド、デビュー戦ハットトリック\n",
      "碑に「名残さない」決断をした遺族たち　大震災から２５年それぞれの思い\n",
      "【新・１月１９日の麒麟がくる】２週遅れでいよいよ大河ドラマスタート！\n",
      "【井上咲楽の本音】「立民」「国民」合流は“学級委員”玉木代表にかかってる！？\n",
      "英王室、ヘンリー王子とメガン妃「春以降 公務から引退」と発表\n",
      "3年連続3冠ならず…みまひな対決早田に軍配 涙の伊藤美誠「悔しいけど負けたからこそまた頑張れる」\n",
      "手術から復帰のホリエモン　美肌のワケは「ＶＩＯ脱毛全部…首から下は全部」\n",
      "昼食は名物「豆アジ天うどん」　将棋女流名人戦第１局\n",
      "選抜女子駅伝北九州大会　デンソーが初優勝、高校の部で神村学園が連覇\n",
      "最後の「センター試験」２日目始まる\n",
      "復活の宇良が勝ち越し　「近大の伊東監督が物言いを付けてくれて」\n",
      "レッズ秋山翔吾が心待ちにする、同学年の田中将大＆マエケンと勝負。\n",
      "東大生　電車内で女子高生の下半身触ったか\n",
      "日本らしさを表現した和風パン　ＨＯＫＵＯ\n",
      "剛力彩芽「高校生以来」のプリクラ公開　ファン驚き「可愛すぎる」「どこのJK」\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://news.yahoo.co.jp/flash'\n",
    "res = requests.get(url)\n",
    "soup = BeautifulSoup(res.content)\n",
    "\n",
    "parent = soup.find('div', 'newsFeed')\n",
    "targets = parent.findAll('div', 'newsFeed_item_title')\n",
    "\n",
    "for target in targets:\n",
    "    print(target.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "###  演習\n",
    "_[日経平均株価](https://www.nikkei.com/markets/worldidx/chart/nk225/)\n",
    "から日経平均を取得してみましょう。_  \n",
    "\n",
    "ヒント : ```<span class = \"economic_value_now a-fs26\">```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 演習\n",
    "_[国内株式](https://www.nikkei.com/markets/worldidx/)\n",
    "から各銘柄と値を全てを出力してみましょう。_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "日経平均（円） 24,041.26\n",
      "JPX日経400 15,543.62\n",
      "日経300 353.73\n",
      "日経500平均（円） 2,280.16\n",
      "日経JAPAN1000 2,065.14\n",
      "日経ジャスダック平均（円） 3,920.58\n",
      "日経平均先物（円）大取,20/03月 ※ 24,030\n",
      "日経平均先物（円）大取,20/06月 ※ 23,850\n",
      "同 夜間取引（円）ヘルプ大取,20/03月 ※ 24,020\n",
      "同 夜間取引（円）ヘルプ大取,20/06月 ※ 23,830\n",
      "TOPIX ※ 1,735.44\n",
      "東証２部総合指数 ※ 7,484.12\n",
      "東証REIT指数 ※ 2,157.72\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.nikkei.com/markets/worldidx/'\n",
    "res = requests.get(url)\n",
    "soup = BeautifulSoup(res.content)\n",
    "table = soup.find('table', 'cmn-table_style1')\n",
    "trs = table.findAll('tr')\n",
    "\n",
    "for tr in trs:\n",
    "    th = tr.find('th')\n",
    "    tds = tr.findAll('td')\n",
    "    print(th.text, tds[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### チャレンジ\n",
    "-[yahooの速報](https://news.yahoo.co.jp/flash)のように送りページがあるサイトの情報をnページ分取得する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "#############\n",
    "# 新登場論点 #\n",
    "############\n",
    "# 辞書\n",
    "# append\n",
    "# pandasのdataframe\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "for i in range(1, 41):\n",
    "    url = 'https://news.yahoo.co.jp/flash?page=' + str(i)\n",
    "    res = requests.get(url)\n",
    "    soup = BeautifulSoup(res.content)\n",
    "\n",
    "    parent = soup.find('div', 'newsFeed')\n",
    "    targets = parent.findAll('div', 'newsFeed_item_title')\n",
    "\n",
    "    for target in targets:\n",
    "        dic = {}\n",
    "        dic['text'] = target.text\n",
    "        results.append(dic)\n",
    "        \n",
    "dataframe = pd.DataFrame(results)\n",
    "dataframe.to_csv('./sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
